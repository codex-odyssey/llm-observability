{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ツールやライブラリ（LangChain）との統合を用いた計装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行に必要な環境変数を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, time\n",
    "\n",
    "# おまじない\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "endpoint = \"http://localhost:3000\"\n",
    "public_key = os.getenv(\"PUBLIC_KEY\")\n",
    "secret_key = os.getenv(\"SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuseが提供するLangChainのCallback実装を初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# 環境変数（LANGFUSE_SECRET_KEY, LANGFUSE_PUBLIC_KEY, LANGFUSE_HOST）を定義でも良い\n",
    "callback_handler = CallbackHandler(\n",
    "    public_key=public_key,\n",
    "    secret_key=secret_key,\n",
    "    host=endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡易的なRAGアプリケーションを構築します。詳細は、[chapter03-03-simple-llm-app-with-rag.ipynb](./chapter03-03-simple-llm-app-with-rag.ipynb)を参照ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xQL完全ガイドは、Prometheus、Grafana Loki、Grafana Tempo などのモニタリングツールで使用されるクエリ言語、PromQL、LogQL、TraceQL について解説したガイドブックです。これらのツールで計測したテレメトリデータから必要な情報を引き出すためのクエリの書き方を学ぶことができます。ガイドブックには、各クエリ言語の解説だけでなく、サンプルアプリや Docker 環境も用意されており、実際に手を動かしながら学ぶことができます。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "xql_doc = WebBaseLoader(\"https://techbookfest.org/product/vwEgK9fAmzRphNukv4E83P?productVariantID=b6iAh0AVyEs4hCUczPiy\").load()\n",
    "\n",
    "if os.getenv(\"COHERE_API_KEY\") == None:\n",
    "    from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    embeddings = OpenAIEmbeddings(api_key=openai_api_key)\n",
    "else:\n",
    "    from langchain_cohere.embeddings import CohereEmbeddings\n",
    "    cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "    embeddings = CohereEmbeddings(\n",
    "        cohere_api_key=cohere_api_key,\n",
    "        model=\"embed-multilingual-v3.0\"\n",
    "    )\n",
    "\n",
    "xql_db = FAISS.from_documents(\n",
    "    documents=xql_doc,\n",
    "    embedding=embeddings\n",
    ")\n",
    "xql_retriever = xql_db.as_retriever()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=\"\"\"\n",
    "あなたは有能なアシスタントです。\n",
    "以下のコンテキストに基づいて質問に対する回答を作成してください。\n",
    "分からない場合は分からないと回答してください。\n",
    "\n",
    "## コンテキスト\n",
    "\n",
    "{context}\n",
    "\n",
    "## 質問\n",
    "\n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "if os.getenv(\"COHERE_API_KEY\") == None:\n",
    "    from langchain_openai.chat_models import ChatOpenAI\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    model = \"gpt-4o-mini\"\n",
    "    chat = ChatOpenAI(api_key=openai_api_key, model=model)\n",
    "else:\n",
    "    from langchain_cohere.chat_models import ChatCohere\n",
    "    cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "    model = \"command-r-plus\"\n",
    "    chat = ChatCohere(cohere_api_key=cohere_api_key, model=model)\n",
    "\n",
    "chain = (\n",
    "    {\"question\": RunnablePassthrough(), \"context\": xql_retriever}\n",
    "    | prompt_template\n",
    "    | chat\n",
    "    | StrOutputParser()\n",
    ")\n",
    "# RAGを行うChainを定義\n",
    "response = chain.invoke(\n",
    "    input=\"xQL完全ガイドってなに？\",\n",
    "    # LangChainのCallback実装をChain実行時のConfigに渡す\n",
    "    config={\"callbacks\": [callback_handler]}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
