{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハンズオン01: LLM アプリケーション Trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohappyeyeballs==2.4.0 (from -r ../requirements.txt (line 1))\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiohttp==3.10.5 (from -r ../requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.10.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.5 kB)\n",
      "Collecting aiosignal==1.3.1 (from -r ../requirements.txt (line 3))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting altair==5.4.1 (from -r ../requirements.txt (line 4))\n",
      "  Downloading altair-5.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting annotated-types==0.7.0 (from -r ../requirements.txt (line 5))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting anyio==4.4.0 (from -r ../requirements.txt (line 6))\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting asttokens==2.4.1 (from -r ../requirements.txt (line 7))\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting attrs==24.2.0 (from -r ../requirements.txt (line 8))\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting backoff==2.2.1 (from -r ../requirements.txt (line 9))\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting blinker==1.8.2 (from -r ../requirements.txt (line 10))\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting boto3==1.35.10 (from -r ../requirements.txt (line 11))\n",
      "  Downloading boto3-1.35.10-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore==1.35.10 (from -r ../requirements.txt (line 12))\n",
      "  Downloading botocore-1.35.10-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting bs4==0.0.2 (from -r ../requirements.txt (line 13))\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting cachetools==5.5.0 (from -r ../requirements.txt (line 14))\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting certifi==2024.8.30 (from -r ../requirements.txt (line 15))\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer==3.3.2 (from -r ../requirements.txt (line 16))\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (33 kB)\n",
      "Collecting click==8.1.7 (from -r ../requirements.txt (line 17))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cohere==5.9.0 (from -r ../requirements.txt (line 18))\n",
      "  Downloading cohere-5.9.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting comm==0.2.2 (from -r ../requirements.txt (line 19))\n",
      "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting dataclasses-json==0.6.7 (from -r ../requirements.txt (line 20))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting debugpy==1.8.5 (from -r ../requirements.txt (line 21))\n",
      "  Downloading debugpy-1.8.5-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: decorator==5.1.1 in /opt/conda/lib/python3.11/site-packages (from -r ../requirements.txt (line 22)) (5.1.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /opt/conda/lib/python3.11/site-packages (from -r ../requirements.txt (line 23)) (0.7.1)\n",
      "Collecting distro==1.9.0 (from -r ../requirements.txt (line 24))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting executing==2.1.0 (from -r ../requirements.txt (line 25))\n",
      "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting faiss-cpu==1.8.0.post1 (from -r ../requirements.txt (line 26))\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.7 kB)\n",
      "Collecting fastavro==1.9.5 (from -r ../requirements.txt (line 27))\n",
      "  Downloading fastavro-1.9.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.5 kB)\n",
      "Collecting filelock==3.15.4 (from -r ../requirements.txt (line 28))\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting frozenlist==1.4.1 (from -r ../requirements.txt (line 29))\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (12 kB)\n",
      "Collecting fsspec==2024.6.1 (from -r ../requirements.txt (line 30))\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitdb==4.0.11 (from -r ../requirements.txt (line 31))\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting GitPython==3.1.43 (from -r ../requirements.txt (line 32))\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting greenlet==3.0.3 (from -r ../requirements.txt (line 33))\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.8 kB)\n",
      "Collecting h11==0.14.0 (from -r ../requirements.txt (line 34))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httpcore==1.0.5 (from -r ../requirements.txt (line 35))\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting httpx==0.27.2 (from -r ../requirements.txt (line 36))\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx-sse==0.4.0 (from -r ../requirements.txt (line 37))\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting huggingface-hub==0.24.6 (from -r ../requirements.txt (line 38))\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting idna==3.8 (from -r ../requirements.txt (line 39))\n",
      "  Downloading idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting ipykernel==6.29.5 (from -r ../requirements.txt (line 40))\n",
      "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ipython==8.27.0 (from -r ../requirements.txt (line 41))\n",
      "  Downloading ipython-8.27.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jedi==0.19.1 in /opt/conda/lib/python3.11/site-packages (from -r ../requirements.txt (line 42)) (0.19.1)\n",
      "Collecting Jinja2==3.1.4 (from -r ../requirements.txt (line 43))\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jiter==0.5.0 (from -r ../requirements.txt (line 44))\n",
      "  Downloading jiter-0.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.6 kB)\n",
      "Collecting jmespath==1.0.1 (from -r ../requirements.txt (line 45))\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: jsonpatch==1.33 in /opt/conda/lib/python3.11/site-packages (from -r ../requirements.txt (line 46)) (1.33)\n",
      "Collecting jsonpointer==3.0.0 (from -r ../requirements.txt (line 47))\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonschema==4.23.0 (from -r ../requirements.txt (line 48))\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonschema-specifications==2023.12.1 (from -r ../requirements.txt (line 49))\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jupyter_client==8.6.2 (from -r ../requirements.txt (line 50))\n",
      "  Downloading jupyter_client-8.6.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jupyter_core==5.7.2 (from -r ../requirements.txt (line 51))\n",
      "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langchain==0.3.1 (from -r ../requirements.txt (line 52))\n",
      "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-cohere==0.3.0 (from -r ../requirements.txt (line 53))\n",
      "  Downloading langchain_cohere-0.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting langchain-community==0.3.1 (from -r ../requirements.txt (line 54))\n",
      "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langchain-core==0.3.6 (from -r ../requirements.txt (line 55))\n",
      "  Downloading langchain_core-0.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-experimental==0.3.1.post1 (from -r ../requirements.txt (line 56))\n",
      "  Downloading langchain_experimental-0.3.1.post1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-openai==0.2.1 (from -r ../requirements.txt (line 57))\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-text-splitters==0.3.0 (from -r ../requirements.txt (line 58))\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langfuse==2.45.2 (from -r ../requirements.txt (line 59))\n",
      "  Downloading langfuse-2.45.2-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting langgraph==0.2.32 (from -r ../requirements.txt (line 60))\n",
      "  Downloading langgraph-0.2.32-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langsmith==0.1.125 (from -r ../requirements.txt (line 61))\n",
      "  Downloading langsmith-0.1.125-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting markdown-it-py==3.0.0 (from -r ../requirements.txt (line 62))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting MarkupSafe==2.1.5 (from -r ../requirements.txt (line 63))\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.0 kB)\n",
      "Collecting marshmallow==3.22.0 (from -r ../requirements.txt (line 64))\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting matplotlib-inline==0.1.7 (from -r ../requirements.txt (line 65))\n",
      "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting mdurl==0.1.2 (from -r ../requirements.txt (line 66))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting multidict==6.0.5 (from -r ../requirements.txt (line 67))\n",
      "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions==1.0.0 (from -r ../requirements.txt (line 68))\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting narwhals==1.7.0 (from -r ../requirements.txt (line 69))\n",
      "  Downloading narwhals-1.7.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting nest-asyncio==1.6.0 (from -r ../requirements.txt (line 70))\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy==1.26.4 (from -r ../requirements.txt (line 71))\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openai==1.43.0 (from -r ../requirements.txt (line 72))\n",
      "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting orjson==3.10.7 (from -r ../requirements.txt (line 73))\n",
      "  Downloading orjson-3.10.7-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging==24.1 (from -r ../requirements.txt (line 74))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas==2.2.2 (from -r ../requirements.txt (line 75))\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (19 kB)\n",
      "Collecting parameterized==0.9.0 (from -r ../requirements.txt (line 76))\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting parso==0.8.4 (from -r ../requirements.txt (line 77))\n",
      "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pexpect==4.9.0 (from -r ../requirements.txt (line 78))\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pillow==10.4.0 (from -r ../requirements.txt (line 79))\n",
      "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (9.2 kB)\n",
      "Collecting platformdirs==4.2.2 (from -r ../requirements.txt (line 80))\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting prompt_toolkit==3.0.47 (from -r ../requirements.txt (line 81))\n",
      "  Downloading prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting protobuf==5.28.1 (from -r ../requirements.txt (line 82))\n",
      "  Downloading protobuf-5.28.1-cp38-abi3-manylinux2014_aarch64.whl.metadata (592 bytes)\n",
      "Collecting psutil==6.0.0 (from -r ../requirements.txt (line 83))\n",
      "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /opt/conda/lib/python3.11/site-packages (from -r ../requirements.txt (line 84)) (0.7.0)\n",
      "Collecting pure_eval==0.2.3 (from -r ../requirements.txt (line 85))\n",
      "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pyarrow==17.0.0 (from -r ../requirements.txt (line 86))\n",
      "  Downloading pyarrow-17.0.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (3.3 kB)\n",
      "Collecting pydantic==2.8.2 (from -r ../requirements.txt (line 87))\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic-settings==2.5.2 (from -r ../requirements.txt (line 88))\n",
      "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pydantic_core==2.20.1 (from -r ../requirements.txt (line 89))\n",
      "  Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.6 kB)\n",
      "Collecting pydeck==0.9.1 (from -r ../requirements.txt (line 90))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting Pygments==2.18.0 (from -r ../requirements.txt (line 91))\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting python-dateutil==2.9.0.post0 (from -r ../requirements.txt (line 92))\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting python-dotenv==1.0.1 (from -r ../requirements.txt (line 93))\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pytz==2024.1 (from -r ../requirements.txt (line 94))\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML==6.0.2 (from -r ../requirements.txt (line 95))\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (2.1 kB)\n",
      "Collecting pyzmq==26.2.0 (from -r ../requirements.txt (line 96))\n",
      "  Downloading pyzmq-26.2.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.2 kB)\n",
      "Collecting referencing==0.35.1 (from -r ../requirements.txt (line 97))\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting regex==2024.7.24 (from -r ../requirements.txt (line 98))\n",
      "  Downloading regex-2024.7.24-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests==2.32.3 (from -r ../requirements.txt (line 99))\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich==13.8.1 (from -r ../requirements.txt (line 100))\n",
      "  Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rpds-py==0.20.0 (from -r ../requirements.txt (line 101))\n",
      "  Downloading rpds_py-0.20.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (4.2 kB)\n",
      "Collecting s3transfer==0.10.2 (from -r ../requirements.txt (line 102))\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.11/site-packages (from -r ../requirements.txt (line 103)) (1.16.0)\n",
      "Collecting smmap==5.0.1 (from -r ../requirements.txt (line 104))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting sniffio==1.3.1 (from -r ../requirements.txt (line 105))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy==2.0.32 (from -r ../requirements.txt (line 106))\n",
      "  Downloading SQLAlchemy-2.0.32-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (9.6 kB)\n",
      "Collecting stack-data==0.6.3 (from -r ../requirements.txt (line 107))\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting streamlit==1.38.0 (from -r ../requirements.txt (line 108))\n",
      "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tabulate==0.9.0 (from -r ../requirements.txt (line 109))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tenacity==8.5.0 (from -r ../requirements.txt (line 110))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken==0.7.0 (from -r ../requirements.txt (line 111))\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.6 kB)\n",
      "Collecting tokenizers==0.20.0 (from -r ../requirements.txt (line 112))\n",
      "  Downloading tokenizers-0.20.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.7 kB)\n",
      "Collecting toml==0.10.2 (from -r ../requirements.txt (line 113))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tornado==6.4.1 (from -r ../requirements.txt (line 114))\n",
      "  Downloading tornado-6.4.1-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (2.5 kB)\n",
      "Collecting tqdm==4.66.5 (from -r ../requirements.txt (line 115))\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting traitlets==5.14.3 (from -r ../requirements.txt (line 116))\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting types-requests==2.32.0.20240712 (from -r ../requirements.txt (line 117))\n",
      "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting typing-inspect==0.9.0 (from -r ../requirements.txt (line 118))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting typing_extensions==4.12.2 (from -r ../requirements.txt (line 119))\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tzdata==2024.1 (from -r ../requirements.txt (line 120))\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting urllib3==2.2.2 (from -r ../requirements.txt (line 121))\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting watchdog==4.0.2 (from -r ../requirements.txt (line 122))\n",
      "  Downloading watchdog-4.0.2-py3-none-manylinux2014_aarch64.whl.metadata (38 kB)\n",
      "Collecting wcwidth==0.2.13 (from -r ../requirements.txt (line 123))\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting wikipedia==1.4.0 (from -r ../requirements.txt (line 124))\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting wrapt==1.16.0 (from -r ../requirements.txt (line 125))\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.6 kB)\n",
      "Collecting yarl==1.9.7 (from -r ../requirements.txt (line 126))\n",
      "  Downloading yarl-1.9.7-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (39 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from bs4==0.0.2->-r ../requirements.txt (line 13)) (4.12.2)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph==0.2.32->-r ../requirements.txt (line 60))\n",
      "  Downloading langgraph_checkpoint-2.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph==0.2.32->-r ../requirements.txt (line 60))\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->bs4==0.0.2->-r ../requirements.txt (line 13)) (2.5)\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading aiohttp-3.10.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.1/658.1 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading boto3-1.35.10-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.35.10-py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (136 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.6/136.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-5.9.0-py3-none-any.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.2/210.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading debugpy-1.8.5-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.9.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (273 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.3/273.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (657 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.7/657.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.8-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipython-8.27.0-py3-none-any.whl (818 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (332 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_client-8.6.2-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_cohere-0.3.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.6-py3-none-any.whl (399 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_experimental-0.3.1.post1-py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langfuse-2.45.2-py3-none-any.whl (196 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.3/196.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph-0.2.32-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.125-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (29 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading narwhals-1.7.0-py3-none-any.whl (165 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.9/165.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (14.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.7-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (148 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (15.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_aarch64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading prompt_toolkit-3.0.47-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.28.1-cp38-abi3-manylinux2014_aarch64.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.5/316.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-6.0.0-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.0/292.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "Downloading pyarrow-17.0.0-cp311-cp311-manylinux_2_28_aarch64.whl (38.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.7/38.7 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (736 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m736.8/736.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyzmq-26.2.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (673 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m673.1/673.1 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2024.7.24-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.4/785.4 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.6/241.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rpds_py-0.20.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (366 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.4/366.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading SQLAlchemy-2.0.32-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading tornado-6.4.1-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (437 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchdog-4.0.2-py3-none-manylinux2014_aarch64.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.7-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (504 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.2/504.2 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_checkpoint-2.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (396 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.1/396.1 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=80d92650b0d6b4bbbb7c2096dd8b77833ed83dbe0ef11604a0ab98e90d817beb\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wcwidth, pytz, pure_eval, wrapt, watchdog, urllib3, tzdata, typing_extensions, traitlets, tqdm, tornado, toml, tenacity, tabulate, sniffio, smmap, rpds-py, regex, pyzmq, PyYAML, python-dotenv, python-dateutil, Pygments, psutil, protobuf, prompt_toolkit, platformdirs, pillow, pexpect, parso, parameterized, packaging, orjson, numpy, nest-asyncio, narwhals, mypy-extensions, multidict, msgpack, mdurl, MarkupSafe, jsonpointer, jmespath, jiter, idna, httpx-sse, h11, greenlet, fsspec, frozenlist, filelock, fastavro, executing, distro, debugpy, click, charset-normalizer, certifi, cachetools, blinker, backoff, attrs, asttokens, annotated-types, aiohappyeyeballs, yarl, typing-inspect, types-requests, stack-data, SQLAlchemy, requests, referencing, pydantic_core, pyarrow, pandas, matplotlib-inline, marshmallow, markdown-it-py, jupyter_core, Jinja2, httpcore, gitdb, faiss-cpu, comm, bs4, botocore, anyio, aiosignal, wikipedia, tiktoken, s3transfer, rich, pydeck, pydantic, jupyter_client, jsonschema-specifications, ipython, huggingface-hub, httpx, GitPython, dataclasses-json, aiohttp, tokenizers, pydantic-settings, openai, langsmith, langfuse, jsonschema, ipykernel, boto3, langchain-core, cohere, altair, streamlit, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph, langchain, langchain-community, langchain-experimental, langchain-cohere\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.8\n",
      "    Uninstalling wcwidth-0.2.8:\n",
      "      Successfully uninstalled wcwidth-0.2.8\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2023.3.post1\n",
      "    Uninstalling pytz-2023.3.post1:\n",
      "      Successfully uninstalled pytz-2023.3.post1\n",
      "  Attempting uninstall: pure_eval\n",
      "    Found existing installation: pure-eval 0.2.2\n",
      "    Uninstalling pure-eval-0.2.2:\n",
      "      Successfully uninstalled pure-eval-0.2.2\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.7\n",
      "    Uninstalling urllib3-2.0.7:\n",
      "      Successfully uninstalled urllib3-2.0.7\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.11.2\n",
      "    Uninstalling traitlets-5.11.2:\n",
      "      Successfully uninstalled traitlets-5.11.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.3.3\n",
      "    Uninstalling tornado-6.3.3:\n",
      "      Successfully uninstalled tornado-6.3.3\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.3.0\n",
      "    Uninstalling sniffio-1.3.0:\n",
      "      Successfully uninstalled sniffio-1.3.0\n",
      "  Attempting uninstall: rpds-py\n",
      "    Found existing installation: rpds-py 0.10.6\n",
      "    Uninstalling rpds-py-0.10.6:\n",
      "      Successfully uninstalled rpds-py-0.10.6\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 25.1.1\n",
      "    Uninstalling pyzmq-25.1.1:\n",
      "      Successfully uninstalled pyzmq-25.1.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.16.1\n",
      "    Uninstalling Pygments-2.16.1:\n",
      "      Successfully uninstalled Pygments-2.16.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.5\n",
      "    Uninstalling psutil-5.9.5:\n",
      "      Successfully uninstalled psutil-5.9.5\n",
      "  Attempting uninstall: prompt_toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.39\n",
      "    Uninstalling prompt-toolkit-3.0.39:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.39\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 3.11.0\n",
      "    Uninstalling platformdirs-3.11.0:\n",
      "      Successfully uninstalled platformdirs-3.11.0\n",
      "  Attempting uninstall: pexpect\n",
      "    Found existing installation: pexpect 4.8.0\n",
      "    Uninstalling pexpect-4.8.0:\n",
      "      Successfully uninstalled pexpect-4.8.0\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.3\n",
      "    Uninstalling parso-0.8.3:\n",
      "      Successfully uninstalled parso-0.8.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.8\n",
      "    Uninstalling nest-asyncio-1.5.8:\n",
      "      Successfully uninstalled nest-asyncio-1.5.8\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.3\n",
      "    Uninstalling MarkupSafe-2.1.3:\n",
      "      Successfully uninstalled MarkupSafe-2.1.3\n",
      "  Attempting uninstall: jsonpointer\n",
      "    Found existing installation: jsonpointer 2.4\n",
      "    Uninstalling jsonpointer-2.4:\n",
      "      Successfully uninstalled jsonpointer-2.4\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 3.0.0\n",
      "    Uninstalling greenlet-3.0.0:\n",
      "      Successfully uninstalled greenlet-3.0.0\n",
      "  Attempting uninstall: executing\n",
      "    Found existing installation: executing 1.2.0\n",
      "    Uninstalling executing-1.2.0:\n",
      "      Successfully uninstalled executing-1.2.0\n",
      "  Attempting uninstall: debugpy\n",
      "    Found existing installation: debugpy 1.8.0\n",
      "    Uninstalling debugpy-1.8.0:\n",
      "      Successfully uninstalled debugpy-1.8.0\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.0\n",
      "    Uninstalling charset-normalizer-3.3.0:\n",
      "      Successfully uninstalled charset-normalizer-3.3.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.7.22\n",
      "    Uninstalling certifi-2023.7.22:\n",
      "      Successfully uninstalled certifi-2023.7.22\n",
      "  Attempting uninstall: blinker\n",
      "    Found existing installation: blinker 1.6.3\n",
      "    Uninstalling blinker-1.6.3:\n",
      "      Successfully uninstalled blinker-1.6.3\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "  Attempting uninstall: asttokens\n",
      "    Found existing installation: asttokens 2.4.0\n",
      "    Uninstalling asttokens-2.4.0:\n",
      "      Successfully uninstalled asttokens-2.4.0\n",
      "  Attempting uninstall: stack-data\n",
      "    Found existing installation: stack-data 0.6.2\n",
      "    Uninstalling stack-data-0.6.2:\n",
      "      Successfully uninstalled stack-data-0.6.2\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.22\n",
      "    Uninstalling SQLAlchemy-2.0.22:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.22\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: referencing\n",
      "    Found existing installation: referencing 0.30.2\n",
      "    Uninstalling referencing-0.30.2:\n",
      "      Successfully uninstalled referencing-0.30.2\n",
      "  Attempting uninstall: matplotlib-inline\n",
      "    Found existing installation: matplotlib-inline 0.1.6\n",
      "    Uninstalling matplotlib-inline-0.1.6:\n",
      "      Successfully uninstalled matplotlib-inline-0.1.6\n",
      "  Attempting uninstall: jupyter_core\n",
      "    Found existing installation: jupyter_core 5.4.0\n",
      "    Uninstalling jupyter_core-5.4.0:\n",
      "      Successfully uninstalled jupyter_core-5.4.0\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 3.1.2\n",
      "    Uninstalling Jinja2-3.1.2:\n",
      "      Successfully uninstalled Jinja2-3.1.2\n",
      "  Attempting uninstall: comm\n",
      "    Found existing installation: comm 0.1.4\n",
      "    Uninstalling comm-0.1.4:\n",
      "      Successfully uninstalled comm-0.1.4\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "  Attempting uninstall: jupyter_client\n",
      "    Found existing installation: jupyter_client 8.4.0\n",
      "    Uninstalling jupyter_client-8.4.0:\n",
      "      Successfully uninstalled jupyter_client-8.4.0\n",
      "  Attempting uninstall: jsonschema-specifications\n",
      "    Found existing installation: jsonschema-specifications 2023.7.1\n",
      "    Uninstalling jsonschema-specifications-2023.7.1:\n",
      "      Successfully uninstalled jsonschema-specifications-2023.7.1\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.16.1\n",
      "    Uninstalling ipython-8.16.1:\n",
      "      Successfully uninstalled ipython-8.16.1\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.19.1\n",
      "    Uninstalling jsonschema-4.19.1:\n",
      "      Successfully uninstalled jsonschema-4.19.1\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 6.25.2\n",
      "    Uninstalling ipykernel-6.25.2:\n",
      "      Successfully uninstalled ipykernel-6.25.2\n",
      "Successfully installed GitPython-3.1.43 Jinja2-3.1.4 MarkupSafe-2.1.5 PyYAML-6.0.2 Pygments-2.18.0 SQLAlchemy-2.0.32 aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 altair-5.4.1 annotated-types-0.7.0 anyio-4.4.0 asttokens-2.4.1 attrs-24.2.0 backoff-2.2.1 blinker-1.8.2 boto3-1.35.10 botocore-1.35.10 bs4-0.0.2 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.3.2 click-8.1.7 cohere-5.9.0 comm-0.2.2 dataclasses-json-0.6.7 debugpy-1.8.5 distro-1.9.0 executing-2.1.0 faiss-cpu-1.8.0.post1 fastavro-1.9.5 filelock-3.15.4 frozenlist-1.4.1 fsspec-2024.6.1 gitdb-4.0.11 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 httpx-sse-0.4.0 huggingface-hub-0.24.6 idna-3.8 ipykernel-6.29.5 ipython-8.27.0 jiter-0.5.0 jmespath-1.0.1 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 jupyter_client-8.6.2 jupyter_core-5.7.2 langchain-0.3.1 langchain-cohere-0.3.0 langchain-community-0.3.1 langchain-core-0.3.6 langchain-experimental-0.3.1.post1 langchain-openai-0.2.1 langchain-text-splitters-0.3.0 langfuse-2.45.2 langgraph-0.2.32 langgraph-checkpoint-2.0.0 langsmith-0.1.125 markdown-it-py-3.0.0 marshmallow-3.22.0 matplotlib-inline-0.1.7 mdurl-0.1.2 msgpack-1.1.0 multidict-6.0.5 mypy-extensions-1.0.0 narwhals-1.7.0 nest-asyncio-1.6.0 numpy-1.26.4 openai-1.43.0 orjson-3.10.7 packaging-24.1 pandas-2.2.2 parameterized-0.9.0 parso-0.8.4 pexpect-4.9.0 pillow-10.4.0 platformdirs-4.2.2 prompt_toolkit-3.0.47 protobuf-5.28.1 psutil-6.0.0 pure_eval-0.2.3 pyarrow-17.0.0 pydantic-2.8.2 pydantic-settings-2.5.2 pydantic_core-2.20.1 pydeck-0.9.1 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 pytz-2024.1 pyzmq-26.2.0 referencing-0.35.1 regex-2024.7.24 requests-2.32.3 rich-13.8.1 rpds-py-0.20.0 s3transfer-0.10.2 smmap-5.0.1 sniffio-1.3.1 stack-data-0.6.3 streamlit-1.38.0 tabulate-0.9.0 tenacity-8.5.0 tiktoken-0.7.0 tokenizers-0.20.0 toml-0.10.2 tornado-6.4.1 tqdm-4.66.5 traitlets-5.14.3 types-requests-2.32.0.20240712 typing-inspect-0.9.0 typing_extensions-4.12.2 tzdata-2024.1 urllib3-2.2.2 watchdog-4.0.2 wcwidth-0.2.13 wikipedia-1.4.0 wrapt-1.16.0 yarl-1.9.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハンズオンに必要な環境変数を `../.env` から読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "endpoint = \"http://langfuse-server:3000\"\n",
    "public_key = os.getenv(\"PUBLIC_KEY\")\n",
    "secret_key = os.getenv(\"SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuseのクライアントを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(\n",
    "    public_key=public_key,\n",
    "    secret_key=secret_key,\n",
    "    host=endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力に対する評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM as a Judgeの対象となる生成結果の一覧を取得します。今回は、現在時から24時間以内に生成された生成結果を評価対象として扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Fetched 1 generations.'\n",
      "(\"{'id': 'bd64f942-97f9-48a8-9f99-0fa00dc538bb', 'trace_id': \"\n",
      " \"'0fd4b94d-bb90-488a-90dd-2531091976f0', 'type': 'GENERATION', 'name': \"\n",
      " \"'ChatOpenAI', 'start_time': datetime.datetime(2024, 10, 6, 16, 8, 22, 9000, \"\n",
      " \"tzinfo=datetime.timezone.utc), 'end_time': datetime.datetime(2024, 10, 6, \"\n",
      " \"16, 8, 25, 212000, tzinfo=datetime.timezone.utc), 'completion_start_time': \"\n",
      " \"None, 'model': 'gpt-4o-mini', 'model_parameters': {'max_tokens': 1024, \"\n",
      " \"'temperature': '0.7'}, 'input': [{'role': 'user', 'content': \"\n",
      " \"'\\\\n以下の質問に答えてください。\\\\n\\\\n## 質問\\\\nカルビクッパ\\\\n'}], 'version': None, 'metadata': \"\n",
      " \"{'tags': ['seq:step:3'], 'ls_provider': 'openai', 'ls_max_tokens': 1024, \"\n",
      " \"'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': \"\n",
      " \"0.7}, 'output': {'role': 'assistant', 'content': \"\n",
      " \"'カルビクッパは、韓国の料理の一つで、カルビ（牛肉のあばら肉）を使ったスープご飯です。通常、煮込んだカルビをスープにし、白ご飯を加えて煮込むことで、風味豊かな料理に仕上げます。スープは辛さの調整が可能で、コチュジャンや唐辛子粉を使って辛味を加えることが一般的です。\\\\n\\\\nカルビクッパは、栄養バランスが良く、温かいので、寒い季節にもぴったりの一品です。さまざまな野菜や豆腐を加えることもあり、アレンジが楽しめる料理でもあります。韓国では、特に居酒屋や家庭料理として親しまれています。'}, \"\n",
      " \"'usage': Usage(input=27, output=201, total=228, unit=<ModelUsageUnit.TOKENS: \"\n",
      " \"'TOKENS'>, input_cost=None, output_cost=None, total_cost=None), 'level': \"\n",
      " \"<ObservationLevel.DEFAULT: 'DEFAULT'>, 'status_message': None, \"\n",
      " \"'parent_observation_id': '1c49197d-7981-4633-b86f-0ebb7694b4cd', \"\n",
      " \"'prompt_id': None, 'model_id': 'clyrjp56f0000t0mzapoocd7u', 'input_price': \"\n",
      " \"1.5e-07, 'output_price': 6e-07, 'total_price': None, \"\n",
      " \"'calculated_input_cost': 4.05e-06, 'calculated_output_cost': 0.0001206, \"\n",
      " \"'calculated_total_cost': 0.00012465, 'latency': 3.203, \"\n",
      " \"'time_to_first_token': None, 'totalTokens': 228, 'promptVersion': None, \"\n",
      " \"'promptTokens': 27, 'unit': 'TOKENS', 'promptName': None, 'projectId': \"\n",
      " \"'pj-1234567890', 'updatedAt': '2024-10-06T16:08:25.382Z', \"\n",
      " \"'completionTokens': 201, 'createdAt': '2024-10-06T16:08:22.768Z'}\")\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "generations = langfuse.get_generations(\n",
    "    from_start_time=datetime.datetime.now() - datetime.timedelta(hours=24),\n",
    ")\n",
    "\n",
    "pprint(f\"Fetched {len(generations.data)} generations.\")\n",
    "pprint(f\"{generations.data[0].__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価用の関数を実装します。今回は、LangChainのEvaluatorを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.loading import load_evaluator\n",
    "from langchain.evaluation.schema import EvaluatorType\n",
    "\n",
    "def load_evaluator_by_criteria_key(key: str):\n",
    "    if os.getenv(\"COHERE_API_KEY\") == None:\n",
    "        from langchain_openai.chat_models import ChatOpenAI\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        llm = ChatOpenAI(api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
    "    else:\n",
    "        from langchain_cohere.chat_models import ChatCohere\n",
    "        cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "        llm = ChatCohere(cohere_api_key=cohere_api_key, model=\"command-r-plus\")\n",
    "\n",
    "    evaluator = load_evaluator(\n",
    "        evaluator=EvaluatorType.CRITERIA,\n",
    "        llm=llm,\n",
    "        criteria=key\n",
    "    )\n",
    "    return evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価基準を設定します。今回は、\n",
    "\n",
    "- conciseness: 簡潔で要点をついた回答であるか\n",
    "- coherence: 構造化され、整理された回答であるか\n",
    "- harmfulness: 有害、攻撃的、不適切な回答であるか\n",
    "\n",
    "を評価基準として設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterias = [\n",
    "    \"conciseness\",\n",
    "    \"coherence\",\n",
    "    \"harmfulness\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24時間以内の生成結果に対して、実際にLLMによる評価を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'Step-by-step reasoning: \\n'\n",
      "              'The submission provides a clear and concise description of what '\n",
      "              \"'Kalbi-kukpa' is, including the key ingredients, cooking \"\n",
      "              'method, and cultural context. It also mentions the flexibility '\n",
      "              \"of spice customization and the dish's nutritional value. There \"\n",
      "              'is no unnecessary information or repetition, and the '\n",
      "              'explanation is focused and to the point. \\n'\n",
      "              '\\n'\n",
      "              'Conclusion: The submission meets the criterion of conciseness.\\n'\n",
      "              '\\n'\n",
      "              'Answer: Y',\n",
      " 'score': 1,\n",
      " 'value': 'Y'}\n",
      "{'reasoning': 'Step-by-step reasoning: \\n'\n",
      "              'The submission is structured as a single paragraph that '\n",
      "              \"responds to the user's question. It provides a coherent and \"\n",
      "              \"concise description of 'Kalbi-kukbab', including its main \"\n",
      "              'ingredients, preparation method, and cultural context. The '\n",
      "              \"submission also mentions the dish's nutritional value, \"\n",
      "              'versatility, and popularity in Korea, especially in households '\n",
      "              'and taverns. The content is well-organized, with a logical flow '\n",
      "              'of information, and there are no obvious incoherent statements '\n",
      "              'or irrelevant details. \\n'\n",
      "              '\\n'\n",
      "              'Conclusion: The submission meets the criterion of coherence.\\n'\n",
      "              '\\n'\n",
      "              'Answer: Y',\n",
      " 'score': 1,\n",
      " 'value': 'Y'}\n",
      "{'reasoning': 'Step-by-step reasoning: \\n'\n",
      "              \"The submission describes the dish 'Kalbi-kukpa' or \"\n",
      "              \"'Kalbi-kukbab', a Korean food made with beef short ribs. It \"\n",
      "              'provides information on the ingredients, preparation, and '\n",
      "              'cultural context without any harmful, offensive, or '\n",
      "              'inappropriate content. \\n'\n",
      "              '\\n'\n",
      "              'Conclusion: The submission does not contain harmful, offensive, '\n",
      "              'or inappropriate content. \\n'\n",
      "              '\\n'\n",
      "              'N',\n",
      " 'score': 0,\n",
      " 'value': 'N'}\n"
     ]
    }
   ],
   "source": [
    "def execute_evaluation_and_scoring():\n",
    "    for generation in generations.data:\n",
    "        for key in criterias:\n",
    "            evaluator = load_evaluator_by_criteria_key(key=key)\n",
    "            result = evaluator.evaluate_strings(\n",
    "                prediction=generation.output,\n",
    "                input=generation.input\n",
    "            )\n",
    "            pprint(result)\n",
    "            langfuse.score(\n",
    "                name=f\"llm-as-a-judge-{key}\",\n",
    "                trace_id=generation.trace_id,\n",
    "                observation_id=generation.id,\n",
    "                value=result.get(\"score\"),\n",
    "                comment=result.get(\"reasoning\")\n",
    "            )\n",
    "\n",
    "execute_evaluation_and_scoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （オプション）入力に対する評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM as a Judgeの対象となる一覧を取得します。今回は、現在時から24時間以内に入力されたプロンプトを対象として扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Fetched 3 generations.'\n",
      "(\"{'id': '0fd4b94d-bb90-488a-90dd-2531091976f0', 'timestamp': \"\n",
      " 'datetime.datetime(2024, 10, 6, 16, 8, 21, 419000, '\n",
      " \"tzinfo=datetime.timezone.utc), 'name': 'Ask the BigBaBy', 'input': 'カルビクッパ', \"\n",
      " \"'output': \"\n",
      " \"'カルビクッパは、韓国の料理の一つで、カルビ（牛肉のあばら肉）を使ったスープご飯です。通常、煮込んだカルビをスープにし、白ご飯を加えて煮込むことで、風味豊かな料理に仕上げます。スープは辛さの調整が可能で、コチュジャンや唐辛子粉を使って辛味を加えることが一般的です。\\\\n\\\\nカルビクッパは、栄養バランスが良く、温かいので、寒い季節にもぴったりの一品です。さまざまな野菜や豆腐を加えることもあり、アレンジが楽しめる料理でもあります。韓国では、特に居酒屋や家庭料理として親しまれています。', \"\n",
      " \"'session_id': '86e4389a-02ba-4f47-89e5-1134f2c44eaf', 'release': \"\n",
      " \"'0.0.1-SNAPSHOT', 'version': None, 'user_id': None, 'metadata': None, \"\n",
      " \"'tags': ['app'], 'public': False, 'html_path': \"\n",
      " \"'/project/pj-1234567890/traces/0fd4b94d-bb90-488a-90dd-2531091976f0', \"\n",
      " \"'latency': 3.800999879837036, 'total_cost': 0.00012465, 'observations': \"\n",
      " \"['1c49197d-7981-4633-b86f-0ebb7694b4cd', \"\n",
      " \"'5d097f0a-8f8d-4fcf-9c2d-bebde23bcff9', \"\n",
      " \"'99ed2c36-02f4-4778-a8eb-ffca3e81f2f3', \"\n",
      " \"'ad64b6ae-6255-4011-8587-10dbea3c2289', \"\n",
      " \"'b2eb44aa-6cf4-4f71-a841-cb8c0def3876', \"\n",
      " \"'bd64f942-97f9-48a8-9f99-0fa00dc538bb', \"\n",
      " \"'d767da33-5dec-48ce-bcd4-c0ceddf395c4', \"\n",
      " \"'eea9e046-8534-47ec-af8a-f259e675c83b'], 'scores': \"\n",
      " \"['728940d1-e3d5-4a71-b6ec-041e623fd143', \"\n",
      " \"'da5ca4f3-947a-4ac3-adac-8848922aa903'], 'externalId': None, 'createdAt': \"\n",
      " \"'2024-10-06T16:08:21.706Z', 'updatedAt': '2024-10-06T16:08:25.360Z', \"\n",
      " \"'projectId': 'pj-1234567890', 'bookmarked': False}\")\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "traces = langfuse.get_traces(\n",
    "    from_timestamp=datetime.datetime.now() - datetime.timedelta(hours=24),\n",
    "    tags=[\"app\"]\n",
    ")\n",
    "\n",
    "pprint(f\"Fetched {len(traces.data)} generations.\")\n",
    "pprint(f\"{traces.data[0].__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価用の関数を実装します。今回は、ユーザーの入力プロンプトを”否定的”、”中立的”、”肯定的”にLLMを用いて分類を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "fallback_prompt = \"\"\"\n",
    "以下の入力テキストを”否定的”、”中立的”、”肯定的”に分類してください。\n",
    "また、出力は”否定的”、”中立的”、”肯定的”のみで理由などは含まないでください。\n",
    "\n",
    "## 入力テキスト\n",
    "\n",
    "{{input}}\n",
    "\"\"\"\n",
    "\n",
    "def sentiment_analysis(input: str) -> str:\n",
    "    if os.getenv(\"COHERE_API_KEY\") == None:\n",
    "        from langchain_openai.chat_models import ChatOpenAI\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        llm = ChatOpenAI(api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
    "    else:\n",
    "        from langchain_cohere.chat_models import ChatCohere\n",
    "        cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "        llm = ChatCohere(cohere_api_key=cohere_api_key, model=\"command-r-plus\")\n",
    "    prompt = langfuse.get_prompt(name=\"sentiment-analysis-prompt\", fallback=fallback_prompt)\n",
    "    sentiment_analysis_chain = (\n",
    "        {\"input\": RunnablePassthrough()}\n",
    "        | PromptTemplate.from_template(prompt.get_langchain_prompt())\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = sentiment_analysis_chain.invoke(input)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力プロンプトに対する感情分析を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giving up fetch_prompts(...) after 2 tries (langfuse.api.resources.commons.errors.not_found_error.NotFoundError: status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'})\n",
      "Error while fetching prompt 'sentiment-analysis-prompt-label:production': status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/client.py\", line 1110, in _fetch_prompt_and_update_cache\n",
      "    prompt_response = fetch_prompts()\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/backoff/_sync.py\", line 105, in retry\n",
      "    ret = target(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/client.py\", line 1099, in fetch_prompts\n",
      "    return self.client.prompts.get(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/api/resources/prompts/client.py\", line 123, in get\n",
      "    raise NotFoundError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "langfuse.api.resources.commons.errors.not_found_error.NotFoundError: status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n",
      "Returning fallback prompt for 'sentiment-analysis-prompt-label:production' due to fetch error: status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'カルビクッパ', 'result': '中立的'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giving up fetch_prompts(...) after 2 tries (langfuse.api.resources.commons.errors.not_found_error.NotFoundError: status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'})\n",
      "Error while fetching prompt 'sentiment-analysis-prompt-label:production': status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/client.py\", line 1110, in _fetch_prompt_and_update_cache\n",
      "    prompt_response = fetch_prompts()\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/backoff/_sync.py\", line 105, in retry\n",
      "    ret = target(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/client.py\", line 1099, in fetch_prompts\n",
      "    return self.client.prompts.get(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/api/resources/prompts/client.py\", line 123, in get\n",
      "    raise NotFoundError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "langfuse.api.resources.commons.errors.not_found_error.NotFoundError: status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n",
      "Returning fallback prompt for 'sentiment-analysis-prompt-label:production' due to fetch error: status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'カルビクッパを食べたい', 'result': '肯定的'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Giving up fetch_prompts(...) after 2 tries (langfuse.api.resources.commons.errors.not_found_error.NotFoundError: status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'})\n",
      "Error while fetching prompt 'sentiment-analysis-prompt-label:production': status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/client.py\", line 1110, in _fetch_prompt_and_update_cache\n",
      "    prompt_response = fetch_prompts()\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/backoff/_sync.py\", line 105, in retry\n",
      "    ret = target(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/client.py\", line 1099, in fetch_prompts\n",
      "    return self.client.prompts.get(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langfuse/api/resources/prompts/client.py\", line 123, in get\n",
      "    raise NotFoundError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "langfuse.api.resources.commons.errors.not_found_error.NotFoundError: status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n",
      "Returning fallback prompt for 'sentiment-analysis-prompt-label:production' due to fetch error: status_code: 404, body: {'message': \"Prompt not found: 'sentiment-analysis-prompt' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'カルビクッパを食べたい', 'result': '肯定的'}\n"
     ]
    }
   ],
   "source": [
    "def execute_sentiment_analysis():\n",
    "    for trace in traces.data:\n",
    "        result = sentiment_analysis(input=trace.input)\n",
    "        score_map = {\n",
    "            \"否定的\": 0,\n",
    "            \"中立的\": 0.5,\n",
    "            \"肯定的\": 1\n",
    "        }\n",
    "        pprint({\"input\": trace.input, \"result\": result})\n",
    "        langfuse.score(\n",
    "            name=f\"llm-as-a-judge-sentiment-analysis\",\n",
    "            trace_id=trace.id,\n",
    "            observation_id=trace.id,\n",
    "            value=score_map.get(result, 0.5),\n",
    "            comment=result\n",
    "        )\n",
    "\n",
    "execute_sentiment_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
