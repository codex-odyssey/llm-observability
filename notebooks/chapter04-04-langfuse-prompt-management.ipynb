{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オブザーバビリティを高める機能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行に必要な環境変数を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, time\n",
    "\n",
    "# おまじない\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "endpoint = \"http://localhost:3000\"\n",
    "public_key = os.getenv(\"PUBLIC_KEY\")\n",
    "secret_key = os.getenv(\"SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロンプト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各トレースを同一グループにするために、セッションIDをUUID v4ベースで生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "# Initialize Langfuse client\n",
    "langfuse = Langfuse(\n",
    "    public_key=public_key,\n",
    "    secret_key=secret_key,\n",
    "    host=endpoint\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロンプトテンプレートの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.model.TextPromptClient at 0x7f196018aba0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a text prompt\n",
    "langfuse.create_prompt(\n",
    "    name=\"test-sdk\",\n",
    "    type=\"text\",\n",
    "    prompt=\"{{topic}}について教えて\",\n",
    "    labels=[\"sdk\"],\n",
    "    config={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.model.TextPromptClient at 0x7f745ff79be0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse.create_prompt(\n",
    "    name=\"test-sdk\",\n",
    "    type=\"text\",\n",
    "    prompt=\"簡潔に{{topic}}について教えて\",\n",
    "    labels=[\"sdk\",\"production\"],\n",
    "    config={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'簡潔に大爆笑一発ギャグについて教えて'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# プロンプトテンプレート`test-sdk\"`を取得\n",
    "langfuse_prompt = langfuse.get_prompt(\"test-sdk\")\n",
    "\n",
    "# 取得したプロンプトから\n",
    "compiled_prompt = langfuse_prompt.compile(topic=\"大爆笑一発ギャグ\")\n",
    "# -> \"As an expert movie critic, do you like Dune 2?\"\n",
    "compiled_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate_env\n",
      "generate\n",
      "<cohere.client.Client object at 0x7f743b636360>\n",
      "{'message': '簡潔に大爆笑一発ギャグについて教えて', 'chat_history': [], 'model': 'command-r-plus', 'temperature': 1.0}\n",
      "basecohere.chat\n",
      "text='一発ギャグとは、1つのフレーズや動作で笑いを取るギャグのことです。代表的なものとしては、「コマネチ」（体操選手のコマネチの真似をする）、「いいんです！」（両手を広げて「いいんです！」と叫ぶ）、「つけ麺、ダクダク」（「つけ麺」と言いながら涙を流す仕草をする）などがあります。一発ギャグは、タイミングや動き、声のトーンなどが重要で、笑いを取るのはなかなか難しいですが、上手く決まるととても盛り上がります。' generation_id='0dbed4e0-590e-4196-ac29-2dea0ac760d4' citations=None documents=None is_search_required=None search_queries=None search_results=None finish_reason='COMPLETE' tool_calls=None chat_history=[Message_User(message='簡潔に大爆笑一発ギャグについて教えて', tool_calls=None, role='USER'), Message_Chatbot(message='一発ギャグとは、1つのフレーズや動作で笑いを取るギャグのことです。代表的なものとしては、「コマネチ」（体操選手のコマネチの真似をする）、「いいんです！」（両手を広げて「いいんです！」と叫ぶ）、「つけ麺、ダクダク」（「つけ麺」と言いながら涙を流す仕草をする）などがあります。一発ギャグは、タイミングや動き、声のトーンなどが重要で、笑いを取るのはなかなか難しいですが、上手く決まるととても盛り上がります。', tool_calls=None, role='CHATBOT')] prompt=None meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(input_tokens=12.0, output_tokens=133.0, search_units=None, classifications=None), tokens=ApiMetaTokens(input_tokens=210.0, output_tokens=133.0), warnings=None) response_id='fedbd6a9-4868-471b-9d61-e28cf34bb1b5'\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "from langfuse.decorators import langfuse_context, observe\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_cohere import ChatCohere\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "callback_handler = CallbackHandler(\n",
    "    public_key=public_key,\n",
    "    secret_key=secret_key,\n",
    "    host=endpoint,\n",
    "    session_id=session_id,\n",
    ")\n",
    "#@observe#(as_type=\"generation\")\n",
    "\n",
    "@observe()\n",
    "def nested_generation():\n",
    "    langchain_prompt = ChatPromptTemplate.from_template(\n",
    "        langfuse_prompt.get_langchain_prompt(),\n",
    "        metadata={\"langfuse_prompt\": langfuse_prompt},\n",
    "    )\n",
    "    langfuse_context.update_current_observation(\n",
    "        prompt=langchain_prompt,\n",
    "    )\n",
    "    model = ChatCohere(\n",
    "        model=\"command-r-plus\",\n",
    "        temperature=1,\n",
    "    )\n",
    "    chain = langchain_prompt | model\n",
    "    chain.invoke(\n",
    "        input={\"topic\": \"大爆笑一発ギャグ\"},\n",
    "        config={\"callbacks\": [callback_handler]},\n",
    "    )\n",
    "\n",
    "    #return langchain_prompt\n",
    "\n",
    "nested_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id='cm2ki8l2g001bu5nhzgiebjij', name='test', description='My first dataset', metadata={'date': '2022-01-01', 'type': 'benchmark', 'author': 'Alice'}, project_id='pj-1234567890', created_at=datetime.datetime(2024, 10, 22, 13, 52, 11, 945000, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 22, 15, 58, 2, 885000, tzinfo=datetime.timezone.utc))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse.create_dataset(\n",
    "    name=\"test\",\n",
    "    # optional description\n",
    "    description=\"My first dataset\",\n",
    "    # optional metadata\n",
    "    metadata={\n",
    "        \"author\": \"Alice\",\n",
    "        \"date\": \"2022-01-01\",\n",
    "        \"type\": \"benchmark\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetItem(id='a54cadf3-ec66-49bd-aff2-46413c1aeeb9', status=<DatasetStatus.ACTIVE: 'ACTIVE'>, input={'text': 'hello world'}, expected_output={'text': 'hello world'}, metadata={'model': 'llama3'}, source_trace_id=None, source_observation_id=None, dataset_id='cm2ki8l2g001bu5nhzgiebjij', dataset_name='test', created_at=datetime.datetime(2024, 10, 22, 15, 59, 11, 538000, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 22, 15, 59, 11, 538000, tzinfo=datetime.timezone.utc))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse.create_dataset_item(\n",
    "    dataset_name=\"test\",\n",
    "    # any python object or value, optional\n",
    "    input={\n",
    "        \"text\": \"hello world\"\n",
    "    },\n",
    "    # any python object or value, optional\n",
    "    expected_output={\n",
    "        \"text\": \"hello world\"\n",
    "    },\n",
    "    # metadata, optional\n",
    "    metadata={\n",
    "        \"model\": \"llama3\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetItem(id='247bb60a-d700-47ef-8d52-0bd01f8e2fe2', status=<DatasetStatus.ACTIVE: 'ACTIVE'>, input={'text': 'hello world'}, expected_output={'text': 'hello world'}, metadata=None, source_trace_id='b35c6305-b639-4670-a755-bfd5e725791f', source_observation_id=None, dataset_id='cm2ki8l2g001bu5nhzgiebjij', dataset_name='test', created_at=datetime.datetime(2024, 10, 22, 16, 2, 22, 455000, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2024, 10, 22, 16, 2, 22, 455000, tzinfo=datetime.timezone.utc))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse.create_dataset_item(\n",
    "    dataset_name=\"test\",\n",
    "    input={ \"text\": \"hello world\" },\n",
    "    expected_output={ \"text\": \"hello world\" },\n",
    "    # link to a trace\n",
    "    source_trace_id=\"b35c6305-b639-4670-a755-bfd5e725791f\",\n",
    "    # optional: link to a specific span, event, or generation\n",
    "    #source_observation_id=\"<observation_id>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import observe\n",
    "\n",
    "@observe()\n",
    "def hello_world(data: str):\n",
    "    print(\"Hello \" + data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse.create_dataset(name=\"japanese_holidays\")\n",
    "local_items = [\n",
    "    {\"input\": {\"year\": \"2024\",\"name\":\"海の日\"}, \"expected_output\": \"2024/07/15\"},\n",
    "    {\"input\": {\"year\": \"2024\",\"name\":\"天皇誕生日\"}, \"expected_output\": \"2024/02/23\"},\n",
    "    {\"input\": {\"year\": \"2024\",\"name\":\"勤労感謝の日\"}, \"expected_output\": \"2024/11/23\"},\n",
    "]\n",
    "for item in local_items:\n",
    "  langfuse.create_dataset_item(\n",
    "      dataset_name=\"japanese_holidays\",\n",
    "      input=item[\"input\"],\n",
    "      expected_output=item[\"expected_output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def run_my_langchain_llm_app(input, callback_handler):\n",
    "  prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"あなたは日本の祝日に詳しい有能なアシスタントです。\"),\n",
    "        (\"user\",\"{year}年の{name}をYYYY/MM/DD形式で回答してください。例えば、元日であれば「2024/01/01」と回答してください。\"),\n",
    "    ]\n",
    "  )\n",
    "  chat = ChatCohere(\n",
    "    model=\"command-r-plus\",\n",
    "    temperature=0,\n",
    "  )\n",
    "\n",
    "  chain = prompt | chat\n",
    "\n",
    "  res = chain.invoke(\n",
    "    input,\n",
    "    config={\"callbacks\":[callback_handler]}\n",
    "  )\n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate_env\n",
      "generate\n",
      "<cohere.client.Client object at 0x7f192d0db620>\n",
      "get_role\n",
      "{'message': '2024年の勤労感謝の日をYYYY/MM/DD形式で回答してください。例えば、元日であれば「2024/01/01」と回答してください。', 'chat_history': [{'role': 'System', 'message': 'あなたは日本の祝日に詳しい有能なアシスタントです。'}], 'model': 'command-r-plus', 'temperature': 1.0}\n",
      "basecohere.chat\n",
      "text='2024/11/23' generation_id='4f18355e-342b-42a3-a42d-be0a20fe4eea' citations=None documents=None is_search_required=None search_queries=None search_results=None finish_reason='COMPLETE' tool_calls=None chat_history=[Message_System(message='あなたは日本の祝日に詳しい有能なアシスタントです。', tool_calls=None, role='SYSTEM'), Message_User(message='2024年の勤労感謝の日をYYYY/MM/DD形式で回答してください。例えば、元日であれば「2024/01/01」と回答してください。', tool_calls=None, role='USER'), Message_Chatbot(message='2024/11/23', tool_calls=None, role='CHATBOT')] prompt=None meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(input_tokens=59.0, output_tokens=10.0, search_units=None, classifications=None), tokens=ApiMetaTokens(input_tokens=259.0, output_tokens=10.0), warnings=None) response_id='a6c36f74-5fbc-48ce-bcd1-fe34f717e00b'\n",
      "2024/11/23\n",
      "2024/11/23\n",
      "validate_env\n",
      "generate\n",
      "<cohere.client.Client object at 0x7f192d52b830>\n",
      "get_role\n",
      "{'message': '2024年の天皇誕生日をYYYY/MM/DD形式で回答してください。例えば、元日であれば「2024/01/01」と回答してください。', 'chat_history': [{'role': 'System', 'message': 'あなたは日本の祝日に詳しい有能なアシスタントです。'}], 'model': 'command-r-plus', 'temperature': 1.0}\n",
      "basecohere.chat\n",
      "text='2024/02/23' generation_id='c5198446-996f-4aea-a94b-c2b63ad58edf' citations=None documents=None is_search_required=None search_queries=None search_results=None finish_reason='COMPLETE' tool_calls=None chat_history=[Message_System(message='あなたは日本の祝日に詳しい有能なアシスタントです。', tool_calls=None, role='SYSTEM'), Message_User(message='2024年の天皇誕生日をYYYY/MM/DD形式で回答してください。例えば、元日であれば「2024/01/01」と回答してください。', tool_calls=None, role='USER'), Message_Chatbot(message='2024/02/23', tool_calls=None, role='CHATBOT')] prompt=None meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(input_tokens=57.0, output_tokens=10.0, search_units=None, classifications=None), tokens=ApiMetaTokens(input_tokens=257.0, output_tokens=10.0), warnings=None) response_id='c1f71324-2d92-42e3-9492-25bc27354e47'\n",
      "2024/02/23\n",
      "2024/02/23\n",
      "validate_env\n",
      "generate\n",
      "<cohere.client.Client object at 0x7f192d673290>\n",
      "get_role\n",
      "{'message': '2024年の海の日をYYYY/MM/DD形式で回答してください。例えば、元日であれば「2024/01/01」と回答してください。', 'chat_history': [{'role': 'System', 'message': 'あなたは日本の祝日に詳しい有能なアシスタントです。'}], 'model': 'command-r-plus', 'temperature': 1.0}\n",
      "basecohere.chat\n",
      "text='2024/07/15' generation_id='e01b4f8b-4391-49be-8055-3bee3092fe63' citations=None documents=None is_search_required=None search_queries=None search_results=None finish_reason='COMPLETE' tool_calls=None chat_history=[Message_System(message='あなたは日本の祝日に詳しい有能なアシスタントです。', tool_calls=None, role='SYSTEM'), Message_User(message='2024年の海の日をYYYY/MM/DD形式で回答してください。例えば、元日であれば「2024/01/01」と回答してください。', tool_calls=None, role='USER'), Message_Chatbot(message='2024/07/15', tool_calls=None, role='CHATBOT')] prompt=None meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(input_tokens=57.0, output_tokens=10.0, search_units=None, classifications=None), tokens=ApiMetaTokens(input_tokens=257.0, output_tokens=10.0), warnings=None) response_id='4dd557e4-1eb9-4f7b-b88b-af7bc8af4f26'\n",
      "2024/07/15\n",
      "2024/07/15\n"
     ]
    }
   ],
   "source": [
    "dataset = langfuse.get_dataset(\"japanese_holidays\")\n",
    "\n",
    "for item in dataset.items:\n",
    "  handler = item.get_langchain_handler(run_name=\"case1\")\n",
    "\n",
    "  completion = run_my_langchain_llm_app(item.input, handler)\n",
    "\n",
    "  exact_match = lambda str1, str2: str1 == str2\n",
    "  handler.trace.score(\n",
    "    name=\"exact_match\",\n",
    "    data_type=\"BOOLEAN\",\n",
    "    value= exact_match(completion.content, item.expected_output)\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
