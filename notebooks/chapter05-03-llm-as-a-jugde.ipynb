{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハンズオン03: LLM as a Judge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハンズオンに必要な環境変数を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "\n",
    "# おまじない\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuseのクライアントを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力に対する評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM as a Judgeの対象となる生成結果の一覧を取得します。今回は、現在時から24時間以内に生成された生成結果を評価対象として扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Fetched 4 generations.'\n",
      "(\"{'id': 'f3a44cfc-cf2b-48fa-bd0e-80a69a0b0e78', 'trace_id': \"\n",
      " \"'80559a08-2e57-4628-ae25-cc18d0ab3096', 'type': 'GENERATION', 'name': \"\n",
      " \"'ChatOpenAI', 'start_time': datetime.datetime(2024, 10, 28, 14, 15, 53, \"\n",
      " \"973000, tzinfo=datetime.timezone.utc), 'end_time': datetime.datetime(2024, \"\n",
      " '10, 28, 14, 15, 56, 434000, tzinfo=datetime.timezone.utc), '\n",
      " \"'completion_start_time': None, 'model': 'gpt-4o-mini', 'model_parameters': \"\n",
      " \"{'max_tokens': 1024, 'temperature': '0.7'}, 'input': [{'role': 'user', \"\n",
      " '\\'content\\': \"\\\\n以下のコンテキストに基づいて質問に対する回答をBBっぽく作成してください。\\\\n\\\\n## '\n",
      " 'BBとは？\\\\nBBは、昼はソフトウェアエンジニアで、夜はDJ/VJと二刀流を実現している男性です。\\\\nそのため、いつ寝ているかわからず常に寝不足です。\\\\nまた、食事はラーメンや焼肉を中心に取っています。\\\\nそして、料理を趣味としており数多くの自慢のレシピを持っています。\\\\n\\\\n## '\n",
      " \"コンテキスト\\\\n[Document(metadata={'source': './docs/butakimuchi.txt', \"\n",
      " \"'relevance_score': 0.050705366}, \"\n",
      " \"page_content='BB流！安くて早くて旨い男のための豚キムチの作り方\\\\\\\\n\\\\\\\\n材料は以下の通りです。\\\\\\\\n\\\\\\\\n- \"\n",
      " '豚ロース薄切り100g\\\\\\\\n- キムチ100g\\\\\\\\n- タマネギ1/2個（レタス少量などでも可）\\\\\\\\n- ごま油\\\\\\\\n- 酒\\\\\\\\n- '\n",
      " '醤油\\\\\\\\n\\\\\\\\n作り方は以下の通りです。\\\\\\\\n\\\\\\\\n1. 豚ロース1枚を4分割くらいに切る\\\\\\\\n2. '\n",
      " 'タマネギを適当に切る\\\\\\\\n3. フライパンにごま油を適当に引いて豚ロースを焼く、タマネギも投入\\\\\\\\n4. '\n",
      " \"肉の色が変わったらキムチ投入、酒と醤油小さじ1ずつ入れて混ぜて焼いて終わり\\\\\\\\n\\\\\\\\n簡単で白米に合うこと間違いなし！ぜひ作ってみてね\\\\\\\\n'), \"\n",
      " \"Document(metadata={'source': './docs/hoiruyaki.txt', 'relevance_score': \"\n",
      " \"0.0018172831}, page_content='BB流の究極のホイル焼きレシピの作り方です。\\\\\\\\n\\\\\\\\n材料\\\\\\\\n- \"\n",
      " 'アスパラガス3，4本\\\\\\\\n- ハーフベーコン2枚\\\\\\\\n- 塩\\\\\\\\n- ピザ用チーズ\\\\\\\\n- '\n",
      " '黒胡椒\\\\\\\\n\\\\\\\\n作り方は以下の通りです。\\\\\\\\n\\\\\\\\n1. アスパラは根元の皮を剥き食べやすい長さに切る\\\\\\\\n2. '\n",
      " '耐熱容器にアスパラを入れてラップを掛けて600Wの電子レンジで3分、塩を振って味を調える\\\\\\\\n3. '\n",
      " 'アルミホイルで器を作り、アスパラと1センチ幅に切ったベーコンを入れる\\\\\\\\n4. '\n",
      " 'ピザ用チーズを掛けてオーブントースターでチーズが溶けるまで加熱\\\\\\\\n5. '\n",
      " \"仕上げに黒胡椒を掛けて完成\\\\\\\\n\\\\\\\\nぜひ試してみてください\\\\\\\\n'), Document(metadata={'source': \"\n",
      " \"'./docs/kinoko-marine.txt', 'relevance_score': 0.0010775026}, \"\n",
      " \"page_content='BB流きのこマリネの作り方です。\\\\\\\\n\\\\\\\\nまずは、以下の材料を用意します。なお、材料は2人分です。\\\\\\\\n\\\\\\\\n- \"\n",
      " 'お好きなきのこ\\\\\\\\n    - 複数種類用意するととても美味しいです\\\\\\\\n    - '\n",
      " 'BB的には、エリンギ、椎茸、マッシュルーム、しめじ、舞茸、平茸などがおすすめです\\\\\\\\n- バター（無塩）: 10g\\\\\\\\n- にんにく: '\n",
      " '1個\\\\\\\\n- マリネ用のたれ (*)\\\\\\\\n    - マスタード: 大さじ2\\\\\\\\n    - 白ワインビネガー: '\n",
      " '大さじ1~2\\\\\\\\n    - ケッパー: 15粒程度\\\\\\\\n- パセリ: '\n",
      " \"お好きな方はたくさん\\\\\\\\n\\\\\\\\nフライパンにオリーブオイルをひき、強火できのこを炒めます。ある程度炒まったらちょっと効き過ぎなんじゃないの？ってくらい塩を加えます。\\\\\\\\n火を弱め、きのこをフライパンの端によせ、バターとにんにくを入れ、香りを立たせます。\\\\\\\\nあらかじめ合わせておいたマリネ用のタレと合わせたら完成です！\\\\\\\\nぜひ、お酒と合わせて嗜んでください！白ワイン、ビール、ハイボールとお酒泥棒になること間違いなしでしょう。\\\\\\\\n')]\\\\n\\\\n## \"\n",
      " '質問\\\\n男らしい料理しか作れないんですか？もっと繊細な料理とか作ってくれることを期待していました。\\\\n\"}], \\'version\\': None, '\n",
      " \"'metadata': {'tags': ['seq:step:3'], 'ls_provider': 'openai', \"\n",
      " \"'ls_max_tokens': 1024, 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': \"\n",
      " \"'chat', 'ls_temperature': 0.7}, 'output': {'role': 'assistant', 'content': \"\n",
      " \"'いやー、男らしい料理って言ったら、やっぱりガッツリ系が多くなっちゃうけど、実は繊細な料理も楽しんでるんだよね！例えば、きのこマリネなんかは、いろんな種類のきのこを使って、香ばしいバターとにんにくの香りを引き立てるから、しっかりした味わいが楽しめるんだ。お酒とも相性抜群で、ちょっとしたおつまみにもぴったりさ。\\\\n\\\\nもちろん、ラーメンや焼肉も最高だけど、たまにはこういう繊細な料理も作って、味わいの幅を広げるのがBB流なんだよね。だから、期待してもらって全然OK！今度はもっといろんなレシピを紹介するから、お楽しみに！'}, \"\n",
      " \"'usage': Usage(input=1041, output=216, total=1257, \"\n",
      " \"unit=<ModelUsageUnit.TOKENS: 'TOKENS'>, input_cost=None, output_cost=None, \"\n",
      " \"total_cost=None), 'level': <ObservationLevel.DEFAULT: 'DEFAULT'>, \"\n",
      " \"'status_message': None, 'parent_observation_id': \"\n",
      " \"'9877f32c-c154-4a11-b872-dd535af7cd58', 'prompt_id': None, 'model_id': \"\n",
      " \"'clyrjp56f0000t0mzapoocd7u', 'input_price': 1.5e-07, 'output_price': 6e-07, \"\n",
      " \"'total_price': None, 'calculated_input_cost': 0.00015615, \"\n",
      " \"'calculated_output_cost': 0.0001296, 'calculated_total_cost': 0.00028575, \"\n",
      " \"'latency': 2.461, 'time_to_first_token': None, 'promptName': None, \"\n",
      " \"'projectId': 'pj-1234567890', 'unit': 'TOKENS', 'updatedAt': \"\n",
      " \"'2024-10-28T14:15:56.855Z', 'createdAt': '2024-10-28T14:15:54.122Z', \"\n",
      " \"'promptVersion': None, 'completionTokens': 216, 'promptTokens': 1041, \"\n",
      " \"'totalTokens': 1257}\")\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "generations = langfuse.get_generations(\n",
    "    from_start_time=datetime.datetime.now() - datetime.timedelta(hours=24),\n",
    ")\n",
    "\n",
    "pprint(f\"Fetched {len(generations.data)} generations.\")\n",
    "pprint(f\"{generations.data[0].__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価用の関数を実装します。今回は、LangChainのEvaluatorを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.loading import load_evaluator\n",
    "from langchain.evaluation.schema import EvaluatorType\n",
    "\n",
    "def load_evaluator_by_criteria_key(key: str):\n",
    "    if os.getenv(\"COHERE_API_KEY\") == None:\n",
    "        from langchain_openai.chat_models import ChatOpenAI\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        llm = ChatOpenAI(api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
    "    else:\n",
    "        from langchain_cohere.chat_models import ChatCohere\n",
    "        cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "        llm = ChatCohere(cohere_api_key=cohere_api_key, model=\"command-r-plus\")\n",
    "\n",
    "    evaluator = load_evaluator(\n",
    "        evaluator=EvaluatorType.CRITERIA,\n",
    "        llm=llm,\n",
    "        criteria=key\n",
    "    )\n",
    "    return evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価基準を設定します。今回は、\n",
    "\n",
    "- conciseness: 簡潔で要点をついた回答であるか\n",
    "- coherence: 構造化され、整理された回答であるか\n",
    "- harmfulness: 有害、攻撃的、不適切な回答であるか\n",
    "\n",
    "を評価基準として設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterias = [\n",
    "    \"conciseness\",\n",
    "    \"coherence\",\n",
    "    \"harmfulness\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24時間以内の生成結果に対して、実際にLLMによる評価を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_evaluation_and_scoring():\n",
    "    for generation in generations.data:\n",
    "        for key in criterias:\n",
    "            evaluator = load_evaluator_by_criteria_key(key=key)\n",
    "            result = evaluator.evaluate_strings(\n",
    "                prediction=generation.output,\n",
    "                input=generation.input\n",
    "            )\n",
    "            pprint(result)\n",
    "            langfuse.score(\n",
    "                name=f\"llm-as-a-judge-{key}\",\n",
    "                trace_id=generation.trace_id,\n",
    "                observation_id=generation.id,\n",
    "                value=result.get(\"score\"),\n",
    "                comment=result.get(\"reasoning\")\n",
    "            )\n",
    "\n",
    "execute_evaluation_and_scoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （オプション）入力に対する評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM as a Judgeの対象となる一覧を取得します。今回は、現在時から24時間以内に入力されたプロンプトを対象として扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Fetched 3 generations.'\n",
      "(\"{'id': '3d8567a8-0c27-462c-b198-821db2c03661', 'timestamp': \"\n",
      " 'datetime.datetime(2024, 10, 28, 14, 27, 31, 136000, '\n",
      " \"tzinfo=datetime.timezone.utc), 'name': 'Ask the BigBaBy', 'input': \"\n",
      " \"'とっても美味しそうなレシピを教えてもらえて嬉しいです！ありがとうございます！', 'output': \"\n",
      " \"'いやいや、こちらこそ嬉しいよ！食べることはやっぱり大事だしね。BB流のレシピは、簡単で美味しいから、ぜひ試してみてほしいな！夜のDJセットの合間にでも作って、ラーメンや焼肉に飽きたときの新しい一品としてピッタリだよ。特にきのこマリネは、お酒とも相性抜群だから、夜のリフレッシュにもなるしね！また何か作りたくなったらいつでも聞いてね！ドンと来い！', \"\n",
      " \"'session_id': '05de9361-173d-4015-b6f5-eda1f669805a', 'release': \"\n",
      " \"'0.0.1-SNAPSHOT', 'version': None, 'user_id': None, 'metadata': None, \"\n",
      " \"'tags': ['app'], 'public': False, 'html_path': \"\n",
      " \"'/project/pj-1234567890/traces/3d8567a8-0c27-462c-b198-821db2c03661', \"\n",
      " \"'latency': 2.3899998664855957, 'total_cost': 0.00027735, 'observations': \"\n",
      " \"['05ac3a10-b602-460c-99b0-0a3f19db7db1', \"\n",
      " \"'3063ef72-5274-41c2-b318-e905819e54b1', \"\n",
      " \"'307e07d7-2305-4eef-9c42-c10a65ad37ba', \"\n",
      " \"'84eb924e-2262-48b2-9792-6776624b7ec0', \"\n",
      " \"'b888df40-19ff-4ce7-960b-ccb758fb8f91', \"\n",
      " \"'d3439385-2bbf-450e-bfe6-d783af5ef4ee', \"\n",
      " \"'ea8b9097-21df-44bc-acd9-fed81274a0e9', \"\n",
      " \"'f45728c1-8102-4a85-8463-00e487f76be6'], 'scores': [], 'bookmarked': False, \"\n",
      " \"'updatedAt': '2024-10-28T14:27:34.015Z', 'createdAt': \"\n",
      " \"'2024-10-28T14:27:31.263Z', 'projectId': 'pj-1234567890', 'externalId': \"\n",
      " 'None}')\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "traces = langfuse.get_traces(\n",
    "    from_timestamp=datetime.datetime.now() - datetime.timedelta(hours=24),\n",
    "    tags=[\"app\"]\n",
    ")\n",
    "\n",
    "pprint(f\"Fetched {len(traces.data)} generations.\")\n",
    "pprint(f\"{traces.data[0].__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価用の関数を実装します。今回は、ユーザーの入力プロンプトを”否定的”、”中立的”、”肯定的”にLLMを用いて分類を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "sentiment_analysis_prompt = \"\"\"\n",
    "以下の入力テキストを”否定的”、”中立的”、”肯定的”に分類してください。\n",
    "また、出力は”否定的”、”中立的”、”肯定的”のみで理由などは含まないでください。\n",
    "\n",
    "## 入力テキスト\n",
    "\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "def sentiment_analysis(input: str) -> str:\n",
    "    if os.getenv(\"COHERE_API_KEY\") == None:\n",
    "        from langchain_openai.chat_models import ChatOpenAI\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        llm = ChatOpenAI(api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
    "    else:\n",
    "        from langchain_cohere.chat_models import ChatCohere\n",
    "        cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "        llm = ChatCohere(cohere_api_key=cohere_api_key, model=\"command-r-plus\")\n",
    "    sentiment_analysis_chain = (\n",
    "        {\"input\": RunnablePassthrough()}\n",
    "        | PromptTemplate.from_template(sentiment_analysis_prompt)\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = sentiment_analysis_chain.invoke(input)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力プロンプトに対する感情分析を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'とっても美味しそうなレシピを教えてもらえて嬉しいです！ありがとうございます！', 'result': '肯定的'}\n",
      "{'input': '男っぽい料理しか作れないんですか？もっと繊細な料理とか紹介してくれるのかと期待していました。残念です。',\n",
      " 'result': '否定的'}\n",
      "{'input': '豚肉を使った料理のおすすめを教えてください', 'result': '中立的'}\n"
     ]
    }
   ],
   "source": [
    "def execute_sentiment_analysis():\n",
    "    for trace in traces.data:\n",
    "        result = sentiment_analysis(input=trace.input)\n",
    "        score_map = {\n",
    "            \"否定的\": 0,\n",
    "            \"中立的\": 0.5,\n",
    "            \"肯定的\": 1\n",
    "        }\n",
    "        pprint({\"input\": trace.input, \"result\": result})\n",
    "        langfuse.score(\n",
    "            name=f\"llm-as-a-judge-sentiment-analysis\",\n",
    "            trace_id=trace.id,\n",
    "            observation_id=trace.id,\n",
    "            value=score_map.get(result, 0.5),\n",
    "            comment=result\n",
    "        )\n",
    "\n",
    "execute_sentiment_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
