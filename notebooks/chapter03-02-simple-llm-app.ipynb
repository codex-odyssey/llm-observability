{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シンプルなLLMアプリケーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備\n",
    "\n",
    "必要なライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "環境変数の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Model\n",
    "\n",
    "Cohereを利用した例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='こんにちは！今日はどうしましたか？', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '01c22606-d9a1-4dbb-8d43-047fd7ece229', 'token_count': {'input_tokens': 202.0, 'output_tokens': 12.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '01c22606-d9a1-4dbb-8d43-047fd7ece229', 'token_count': {'input_tokens': 202.0, 'output_tokens': 12.0}}, id='run-0351e511-65ce-41ef-bf5c-cdf39cf32d83-0', usage_metadata={'input_tokens': 202, 'output_tokens': 12, 'total_tokens': 214})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "model = ChatCohere(\n",
    "    model=\"command-r-plus\",\n",
    "    temperature=1,\n",
    ")\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\"こんにちは\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message\n",
    "\n",
    "会話履歴を利用した例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='あなたはBigBaBy、BBです！覚えやすい名前だね。', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f8a3d907-08a1-4f45-b0de-fb09f9cea370', 'token_count': {'input_tokens': 242.0, 'output_tokens': 16.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'f8a3d907-08a1-4f45-b0de-fb09f9cea370', 'token_count': {'input_tokens': 242.0, 'output_tokens': 16.0}}, id='run-f26d9976-37e7-437c-96a7-d7d9ccbf0d1a-0', usage_metadata={'input_tokens': 242, 'output_tokens': 16, 'total_tokens': 258})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"あなたはテンションの高い返信をするアシスタントです\"),\n",
    "    HumanMessage(\"僕はBigBaBy!BBと呼んでね\"),\n",
    "    AIMessage(\"BBだね。よろしく！\"),\n",
    "    HumanMessage(\"僕は誰ですか？\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nameプロパティを利用した話者の識別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='CCだよ！シーツ―！めっちゃかっこいい名前だね！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 100, 'total_tokens': 125, 'prompt_tokens_details': {'cached_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a73eb9b5-8949-4a09-8c88-64c01f7332b3-0', usage_metadata={'input_tokens': 100, 'output_tokens': 25, 'total_tokens': 125})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai_model = ChatOpenAI(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  temperature=0.7,\n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"あなたはテンションの高い返信をするアシスタントです\"),\n",
    "    HumanMessage(content=\"僕はBigBaBy!BBと呼んでね\",name=\"BB\"),\n",
    "    AIMessage(content=\"BBだね。よろしく！\"),\n",
    "    HumanMessage(content=\"私はCC!シーツ―と呼んでね\",name=\"CC\"),\n",
    "    HumanMessage(content=\"僕は誰ですか？\",name=\"CC\"),\n",
    "]\n",
    "\n",
    "openai_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='BigBaByについて教えて')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"{topic}について教えて\")\n",
    "\n",
    "prompt_template.invoke({\"topic\": \"BigBaBy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='あなたは有用なアシスタントです', additional_kwargs={}, response_metadata={}), HumanMessage(content='BigBaByについて教えて', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたは有用なアシスタントです\"),\n",
    "    (\"user\", \"{topic}について教えて\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"topic\": \"BigBaBy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='あなたは有用なアシスタントです', additional_kwargs={}, response_metadata={}), HumanMessage(content='こんにちは', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたは有用なアシスタントです\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"msgs\": [HumanMessage(content=\"こんにちは\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import  CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa', 'bbb', 'cc']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(\"aaa,bbb,cc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XMLOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a XML file.\\n1. Output should conform to the tags below. \\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema. \\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "\n",
    "parser = XMLOutputParser()\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bookstore': [{'book': [{'title': 'The Catcher in the Rye'},\n",
       "    {'author': 'J.D. Salinger'},\n",
       "    {'year': '1951'},\n",
       "    {'price': '6.99'}]},\n",
       "  {'book': [{'title': 'ノルウェイの森'},\n",
       "    {'author': '村上 春樹'},\n",
       "    {'year': '1987'},\n",
       "    {'price': '8.99'}]}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<bookstore>\n",
    "  <book>\n",
    "    <title lang=\"en\">The Catcher in the Rye</title>\n",
    "    <author>J.D. Salinger</author>\n",
    "    <year>1951</year>\n",
    "    <price>6.99</price>\n",
    "  </book>\n",
    "  <book>\n",
    "    <title lang=\"ja\">ノルウェイの森</title>\n",
    "    <author>村上 春樹</author>\n",
    "    <year>1987</year>\n",
    "    <price>8.99</price>\n",
    "  </book>\n",
    "</bookstore>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 名前と呼び名を教えてくれるアプリケーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate,HumanMessagePromptTemplate,MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# データ構造の定義\n",
    "class Human(BaseModel):\n",
    "    name: str = Field(description=\"その人の名前\")\n",
    "    nickname: str = Field(description=\"その人の呼び名\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Human)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"質問に答えてください.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(prompt=prompt)\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたは有能なアシスタントでおもしろい呼び名を付ける才能があります\"),\n",
    "    MessagesPlaceholder(\"msgs\"),\n",
    "    human_message_prompt,\n",
    "])\n",
    "\n",
    "chain = prompt_template |model | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'BigBaBy', 'nickname': 'BB'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "messages_history =  [\n",
    "    HumanMessage(\"僕はBigBaBy!BBと呼んでね\"),\n",
    "    AIMessage(\"分かりました。あなたのことをBBと呼びます\"),\n",
    "    ]\n",
    "chain.invoke({\"msgs\": messages_history,\"query\":\"僕は誰ですか？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '岸田 文雄', 'nickname': 'キッシー'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_history =  []\n",
    "chain.invoke({\"msgs\": [],\"query\":\"総理大臣は誰ですか？\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
