{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDKを用いた計装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行に必要な環境変数を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, time\n",
    "\n",
    "# おまじない\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangfuseのSDKクライアントを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@obserbe()`デコレーターを用いてTraceと各種Observation(Span/Generation)の確認をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meet the BigBaBy!\n",
      "response='喜んでいただけるか分かりませんが、いくつかおすすめの肉料理を紹介します。\\n\\n- ローストビーフ： 牛肉の塊をオーブンでゆっくりと焼き上げた料理です。ジューシーでやわらかな食感と、深い味わいが魅力です。\\n- 豚の角煮： 豚バラ肉を醤油や砂糖などで長時間煮込んだ料理です。とろけるような食感と、甘辛い味付けがご飯にもお酒にもよく合います。\\n- チキンティッカ： インド料理のグリルチキンです。ヨーグルトと香辛料に漬け込んだ鶏肉を串に刺して焼き上げます。スパイシーでジューシーな味わいが楽しめます。\\n- ラムチョップ： 子羊のリブ（あばら骨）部分を使った料理です。骨付き肉をグリルやソテーで焼き上げ、香草やスパイスで味付けします。やわらかな食感と独特の風味が魅力です。\\n- 牛タンのステーキ： 牛タンを厚切りにしてステーキにした料理です。やわらかな食感と、牛肉とはまた違った深い味わいが楽しめます。\\n\\n以上、お口に合うものが見つかれば幸いです。'\n"
     ]
    }
   ],
   "source": [
    "from langfuse.decorators import observe, langfuse_context\n",
    "\n",
    "@observe()\n",
    "def meet_the_bigbaby():\n",
    "    print(\"Meet the BigBaBy!\")\n",
    "\n",
    "@observe(name=\"Search the BigBaBy's dictionary\")\n",
    "def search_the_bigbaby_dict():\n",
    "    time.sleep(2)\n",
    "\n",
    "@observe(name=\"Ask the BigBaBy\", as_type=\"generation\")\n",
    "def ask_the_bigbaby(query: str):\n",
    "    if os.getenv(\"COHERE_API_KEY\") == None:\n",
    "        from langchain_openai.chat_models import ChatOpenAI\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        model = \"gpt-4o-mini\"\n",
    "        llm = ChatOpenAI(api_key=openai_api_key, model=model)\n",
    "    else:\n",
    "        from langchain_cohere.chat_models import ChatCohere\n",
    "        cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "        model = \"command-r-plus\"\n",
    "        llm = ChatCohere(cohere_api_key=cohere_api_key, model=model)\n",
    "    input = [\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    result = llm.invoke(input=input)\n",
    "    return result.content\n",
    "\n",
    "@observe(name=\"Ask the BigBaby\")\n",
    "def main():\n",
    "    meet_the_bigbaby()\n",
    "    search_the_bigbaby_dict()\n",
    "    return ask_the_bigbaby(query=\"肉料理のおすすめ教えて\")\n",
    "\n",
    "response = main()\n",
    "print(f\"{response=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Level SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 属性情報を付与しない実行例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low-Level SDKを用いてTraceと各種Observation(Event/Span/Generation)の確認をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.client.StatefulGenerationClient at 0x7f055907fa10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traceを作成する\n",
    "trace = langfuse.trace(\n",
    "    name=\"Ask the BigBaBy\"\n",
    ")\n",
    "\n",
    "# Observation - EventをTraceに追加する\n",
    "event = trace.event(\n",
    "    name=\"Meet the BigBaBy\"\n",
    ")\n",
    "\n",
    "# Observation - SpanをTraceに追加する\n",
    "span = trace.span(\n",
    "    name=\"Search the BigBaBy's dictionary\"\n",
    ")\n",
    "# 2秒間スリープ（同期コールする検索システムを想定）\n",
    "time.sleep(2)\n",
    "span.end()\n",
    "\n",
    "if os.getenv(\"COHERE_API_KEY\") == None:\n",
    "    from langchain_openai.chat_models import ChatOpenAI\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    model = \"gpt-4o-mini\"\n",
    "    llm = ChatOpenAI(api_key=openai_api_key, model=model)\n",
    "else:\n",
    "    from langchain_cohere.chat_models import ChatCohere\n",
    "    cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "    model = \"command-r-plus\"\n",
    "    llm = ChatCohere(cohere_api_key=cohere_api_key, model=model)\n",
    "\n",
    "input = [\n",
    "    {\"role\": \"user\", \"content\": \"おすすめの肉料理おしえて\"}\n",
    "]\n",
    "\n",
    "generation = trace.generation(\n",
    "    name=\"Ask the BigBaBy\",\n",
    "    model=model,\n",
    "    input=input\n",
    ")\n",
    "\n",
    "result = llm.invoke(input=input)\n",
    "\n",
    "generation.end(\n",
    "    output=result.content,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 属性情報を付与した実行例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "属性情報などを追加した版です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.client.StatefulTraceClient at 0x7f057249d7d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traceを作成する\n",
    "trace = langfuse.trace(\n",
    "    name=\"Ask the BigBaBy\"\n",
    ")\n",
    "\n",
    "trace_id = trace.id\n",
    "\n",
    "# Observation - EventをTraceに追加する\n",
    "event = trace.event(\n",
    "    name=\"Meet the BigBaBy\"\n",
    ")\n",
    "\n",
    "# Observation - SpanをTraceに追加する\n",
    "span = trace.span(\n",
    "    name=\"Search the BigBaBy's dictionary\"\n",
    ")\n",
    "# 2秒間スリープ（同期コールする検索システムを想定）\n",
    "time.sleep(2)\n",
    "# ダミーの検索結果\n",
    "search_result = {\n",
    "    \"recipes\": [{\n",
    "        \"roast-beaf\": \"ローストビーフ： 牛肉の塊をオーブンで焼いた料理で...\"\n",
    "    }]\n",
    "}\n",
    "span.end()\n",
    "span.update(\n",
    "    input=\"おすすめの肉料理おしえて\",\n",
    "    output=search_result\n",
    ")\n",
    "\n",
    "if os.getenv(\"COHERE_API_KEY\") == None:\n",
    "    from langchain_openai.chat_models import ChatOpenAI\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    model = \"gpt-4o-mini\"\n",
    "    llm = ChatOpenAI(api_key=openai_api_key, model=model)\n",
    "else:\n",
    "    from langchain_cohere.chat_models import ChatCohere\n",
    "    cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "    model = \"command-r-plus\"\n",
    "    llm = ChatCohere(cohere_api_key=cohere_api_key, model=model)\n",
    "\n",
    "input = [\n",
    "    {\"role\": \"user\", \"content\": \"おすすめの肉料理おしえて\"}\n",
    "]\n",
    "\n",
    "generation = trace.generation(\n",
    "    name=\"Ask the BigBaBy\",\n",
    "    model=model,\n",
    "    input=input\n",
    ")\n",
    "\n",
    "result = llm.invoke(input=input)\n",
    "\n",
    "generation.end(\n",
    "    output=result.content,\n",
    ")\n",
    "\n",
    "trace.update(\n",
    "    input=\"おすすめの肉料理おしえて\",\n",
    "    output=result.content\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
